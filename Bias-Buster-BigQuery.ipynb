{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "cell_execution_strategy": "setup",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import gradio as gr\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "import re\n",
        "from google.cloud import bigquery\n",
        "import bigframes\n",
        "\n",
        "# Setup\n",
        "os.environ[\"GOOGLE_CLOUD_PROJECT\"] = \"bias-buster-471818\"\n",
        "os.environ[\"BIGFRAMES_LOCATION\"] = \"us-central1\"\n",
        "\n",
        "PROJECT_ID = \"bias-buster-471818\"\n",
        "DATASET_ID = \"bias_buster_dataset\"\n",
        "TABLE_ID = \"news_articles_placeholder\"\n",
        "MODEL_ID = f\"{PROJECT_ID}.{DATASET_ID}.gemini_flash_model\"\n",
        "\n",
        "client = bigquery.Client()\n",
        "bf = bigframes.connect()\n",
        "\n",
        "# Shared analyst prompt\n",
        "ANALYST_PROMPT = \"\"\"You are a media analyst tasked with identifying and documenting biases in news reporting. Based *only* on the provided excerpts, perform a detailed analysis and report on the following aspects:\n",
        "\n",
        "1.  **Framing Bias:** How is the story being framed? What is the central narrative or perspective being promoted? Is there a particular angle (e.g., political, economic, social) that is being emphasized?\n",
        "2.  **Confirmation Bias:** Are the excerpts selectively choosing information that confirms a pre-existing belief or hypothesis? Point to specific examples where this might be occurring.\n",
        "3.  **Sensationalism:** Is the language used overly dramatic or inflammatory? Identify any use of hyperbole, emotionally charged words, or shocking imagery intended to grab the reader's attention rather than inform them.\n",
        "4.  **Selection Bias:** What information seems to be included or excluded? Are certain voices, perspectives, or facts missing? How does this selective inclusion/exclusion shape the overall message?\n",
        "5.  **Placement Bias:** If applicable, consider the placement of information within the excerpts. Is a particular point of view given more prominence by being placed at the beginning or end of a paragraph or article?\n",
        "6.  **Omission Bias:** What facts or perspectives are left out entirely? Are key details or counter-arguments missing that would provide a more complete picture?\n",
        "7.  **Propaganda and Spin:** Is there evidence of a deliberate attempt to manipulate public opinion? Look for signs of \"spin\" - the strategic presentation of information to favor a particular outcome or point of view.\n",
        "8.  **Sentiment and Tone:** Describe the overall sentiment and tone of the excerpts. Is it positive, negative, neutral, or something else? Is the tone consistent, or does it shift?\n",
        "9.  **Social Implications:** Based on the biases identified, what are the potential social implications of this type of reporting? How might this coverage influence public perception, policy decisions, or social cohesion?\n",
        "\n",
        "Provide your analysis in a structured, point-by-point format, citing specific phrases or sentences from the provided text to support each of your findings. Do not introduce any outside information or personal opinions.\"\"\"\n",
        "\n",
        "# Get Unique Topics\n",
        "def get_unique_topics():\n",
        "    sql = f\"\"\"\n",
        "    SELECT DISTINCT topic\n",
        "      FROM `{PROJECT_ID}.{DATASET_ID}.{TABLE_ID}`,\n",
        "           UNNEST(topics) AS topic\n",
        "     WHERE topic IS NOT NULL\n",
        "       AND LENGTH(TRIM(topic)) > 0\n",
        "    \"\"\"\n",
        "    df = client.query(sql).to_dataframe()\n",
        "    cats = df['topic'].dropna().unique().tolist()\n",
        "    return sorted({t.split('->')[0] for t in cats})\n",
        "\n",
        "unique_topics = get_unique_topics()\n",
        "default_topic = unique_topics[0] if unique_topics else \"\"\n",
        "\n",
        "# Summarize the selected excerpts as a batch\n",
        "def generate_summary_for_articles(df):\n",
        "    snippets = df['trimmed_text'].str[:500].tolist()\n",
        "    joined = \"\\n\\n---\\n\\n\".join(snippets)\n",
        "    full_prompt = f\"{ANALYST_PROMPT}\\n\\nExcerpts:\\n\\n{joined}\"\n",
        "\n",
        "    job_config = bigquery.QueryJobConfig(\n",
        "        query_parameters=[\n",
        "            bigquery.ScalarQueryParameter(\"prompt\", \"STRING\", full_prompt)\n",
        "        ]\n",
        "    )\n",
        "    sql = f\"\"\"\n",
        "    SELECT ml_generate_text_llm_result AS summary\n",
        "      FROM ML.GENERATE_TEXT(\n",
        "        MODEL `{MODEL_ID}`,\n",
        "        (SELECT @prompt AS prompt),\n",
        "        STRUCT(TRUE AS flatten_json_output)\n",
        "      )\n",
        "    \"\"\"\n",
        "    out = client.query(sql, job_config=job_config).to_dataframe()\n",
        "    return out['summary'].iloc[0] if not out.empty else \"No summary available.\"\n",
        "\n",
        "# Run Gemini Flash on a temp table\n",
        "def run_generate_text(input_df, prompt_col, temp_table_name):\n",
        "    tmp_id = f\"{PROJECT_ID}.{DATASET_ID}.{temp_table_name}\"\n",
        "    upload_df = input_df[['trimmed_text', prompt_col]].rename(columns={prompt_col: 'prompt'})\n",
        "    job = client.load_table_from_dataframe(\n",
        "        upload_df,\n",
        "        tmp_id,\n",
        "        job_config=bigquery.LoadJobConfig(write_disposition=\"WRITE_TRUNCATE\")\n",
        "    )\n",
        "    job.result()\n",
        "    sql = f\"\"\"\n",
        "    SELECT trimmed_text,\n",
        "           ml_generate_text_llm_result AS result\n",
        "      FROM ML.GENERATE_TEXT(\n",
        "        MODEL `{MODEL_ID}`,\n",
        "        TABLE `{tmp_id}`,\n",
        "        STRUCT(TRUE AS flatten_json_output)\n",
        "      )\n",
        "    \"\"\"\n",
        "    return client.query(sql).to_dataframe()\n",
        "\n",
        "# Robust parse: catch both numbered and bulleted headings\n",
        "def parse_analysis(text):\n",
        "    bias_keys = [\n",
        "        \"Framing Bias\",\"Confirmation Bias\",\"Sensationalism\",\n",
        "        \"Selection Bias\",\"Placement Bias\",\"Omission Bias\",\n",
        "        \"Propaganda and Spin\"\n",
        "    ]\n",
        "    bullets = []\n",
        "    for key in bias_keys:\n",
        "        # look for bolded heading\n",
        "        pat_bold = re.compile(rf\"\\*\\*{re.escape(key)}\\*\\*:\\s*([^\\n]+)\", re.IGNORECASE)\n",
        "        m = pat_bold.search(text)\n",
        "        if not m:\n",
        "            # fallback: plain heading\n",
        "            pat_plain = re.compile(rf\"{re.escape(key)}:\\s*([^\\n]+)\", re.IGNORECASE)\n",
        "            m = pat_plain.search(text)\n",
        "        if m:\n",
        "            val = m.group(1).strip()\n",
        "            if val and not val.lower().startswith(\"none\"):\n",
        "                bullets.append(f\"- **{key}**: {val}\")\n",
        "    score = round(len(bullets) / len(bias_keys) * 10, 1)\n",
        "    if not bullets:\n",
        "        bullets = [\"- **No biases detected**\"]\n",
        "    return \"\\n\".join(bullets), score\n",
        "\n",
        "# Sentiment Distribution\n",
        "def generate_sentiment_plot(grid, topic):\n",
        "    fig = px.histogram(\n",
        "        grid, x='Sentiment', color='Sentiment',\n",
        "        title=f\"Sentiment Distribution for '{topic}'\", template=\"plotly_dark\"\n",
        "    )\n",
        "    fig.update_layout(height=400)\n",
        "    return fig\n",
        "\n",
        "# Forecast Bias Score\n",
        "def generate_forecast_plot(grid, topic):\n",
        "    df2 = grid.dropna(subset=['Published']).copy()\n",
        "    df2['Published'] = pd.to_datetime(df2['Published'])\n",
        "    df2['bias_score'] = df2['Bias Score'].fillna(0)\n",
        "    bf_df = bf.read_pandas(df2[['Published','bias_score']].sort_values('Published'))\n",
        "    if bf_df.shape[0] < 2:\n",
        "        return px.scatter(title=\"Not enough data points for forecasting.\")\n",
        "    fc = bf_df.ai.forecast(\"Published\",\"bias_score\",horizon=10).to_pandas()\n",
        "    fig = px.line(\n",
        "        fc, x='forecast_timestamp', y='forecast_value',\n",
        "        title=f\"Forecasted Bias Score for '{topic}'\", template=\"plotly_dark\"\n",
        "    )\n",
        "    fig.add_scatter(\n",
        "        x=fc['forecast_timestamp'],\n",
        "        y=fc['prediction_interval_upper_bound'],\n",
        "        mode='lines', line=dict(dash='dot', color='lightgray'),\n",
        "        name='Upper Bound'\n",
        "    )\n",
        "    fig.add_scatter(\n",
        "        x=fc['forecast_timestamp'],\n",
        "        y=fc['prediction_interval_lower_bound'],\n",
        "        mode='lines', line=dict(dash='dot', color='lightgray'),\n",
        "        name='Lower Bound'\n",
        "    )\n",
        "    fig.update_layout(height=400)\n",
        "    return fig\n",
        "\n",
        "# Bias Score Heatmap\n",
        "def generate_bias_heatmap(grid, topic):\n",
        "    fig = px.density_heatmap(\n",
        "        grid, x='Sentiment', y='Bias Score',\n",
        "        nbinsx=3, nbinsy=10,\n",
        "        title=f\"Bias Score Heatmap for '{topic}'\",\n",
        "        template=\"plotly_dark\", color_continuous_scale='reds'\n",
        "    )\n",
        "    fig.update_layout(height=400)\n",
        "    return fig\n",
        "\n",
        "# Bias Score Bar Chart\n",
        "def generate_bias_bar_chart(grid, topic):\n",
        "    fig = px.bar(\n",
        "        grid, x='Title', y='Bias Score',\n",
        "        title=f\"Bias Score per Article in '{topic}'\", template=\"plotly_dark\"\n",
        "    )\n",
        "    fig.update_layout(height=400, xaxis_tickangle=-45)\n",
        "    return fig\n",
        "\n",
        "# Main Dashboard Logic\n",
        "def update_dashboard(topic):\n",
        "    # 1) Load & dedupe\n",
        "    sql = f\"\"\"\n",
        "    SELECT title, author, published, sentiment,\n",
        "           LEFT(text, 3000) AS trimmed_text\n",
        "      FROM `{PROJECT_ID}.{DATASET_ID}.{TABLE_ID}`,\n",
        "           UNNEST(topics) AS topic_name\n",
        "     WHERE LOWER(topic_name) LIKE LOWER('%{topic}%')\n",
        "     LIMIT 10\n",
        "    \"\"\"\n",
        "    df = client.query(sql).to_dataframe()\n",
        "    df = df.drop_duplicates(subset=['trimmed_text']).reset_index(drop=True)\n",
        "\n",
        "    if df.empty:\n",
        "        empty_cols = ['Title','Author','Published','Sentiment','Biases','Bias Score']\n",
        "        return (\n",
        "            \"No summary available for these articles.\",\n",
        "            pd.DataFrame(columns=empty_cols),\n",
        "            px.scatter(title=\"No data\"),\n",
        "            px.scatter(title=\"No data\"),\n",
        "            px.scatter(title=\"No data\"),\n",
        "            px.scatter(title=\"No data\")\n",
        "        )\n",
        "\n",
        "    # 2) Batch summary\n",
        "    summary_text = generate_summary_for_articles(df)\n",
        "    summary_md = f\"### Analysis of selected articles on '{topic}'\\n\\n{summary_text}\"\n",
        "\n",
        "    # 3) Per-article analysis\n",
        "    df['analysis_prompt'] = ANALYST_PROMPT + \"\\n\\nExcerpt:\\n\\n\" + df['trimmed_text']\n",
        "    analysis_df = run_generate_text(df, 'analysis_prompt', 'tmp_analysis')\n",
        "\n",
        "    merged = df.merge(\n",
        "        analysis_df, on='trimmed_text', how='left'\n",
        "    ).rename(columns={'result':'analysis_output'})\n",
        "\n",
        "    # 4) Parse biases & scores\n",
        "    parsed = merged['analysis_output'].fillna(\"\").map(parse_analysis)\n",
        "    merged['Biases'], merged['Bias Score'] = zip(*parsed)\n",
        "\n",
        "    # 5) Build grid\n",
        "    grid = merged[[\n",
        "        'title','author','published','sentiment','Biases','Bias Score'\n",
        "    ]].copy()\n",
        "    grid.columns = ['Title','Author','Published','Sentiment','Biases','Bias Score']\n",
        "\n",
        "    # 6) Generate visuals\n",
        "    sent_plot = generate_sentiment_plot(grid, topic)\n",
        "    fc_plot = generate_forecast_plot(grid, topic)\n",
        "    hm_plot = generate_bias_heatmap(grid, topic)\n",
        "    bc_plot = generate_bias_bar_chart(grid, topic)\n",
        "\n",
        "    return summary_md, grid, sent_plot, fc_plot, hm_plot, bc_plot\n",
        "\n",
        "# Gradio UI\n",
        "with gr.Blocks(theme=gr.themes.Soft(), title=\"Bias Intelligence Dashboard\") as demo:\n",
        "    gr.Markdown(\"# <div style='text-align: center; font-size: 2.5em; font-weight: bold;'>Bias Intelligence Dashboard</div>\")\n",
        "    gr.Markdown(\"<div style='text-align: center; font-size: 1.2em; color: #666;'>See Beyond the Story: Bias Under the Lens. Powered by BigQuery & Gemini</div>\")\n",
        "\n",
        "    topic_selector = gr.Dropdown(unique_topics, default_topic, label=\"Select Topic\")\n",
        "    summary_out = gr.Markdown()\n",
        "    ai_output_grid = gr.Dataframe(\n",
        "        headers=[\"Title\",\"Author\",\"Published\",\"Sentiment\",\"Biases\",\"Bias Score\"],\n",
        "        interactive=False\n",
        "    )\n",
        "\n",
        "    with gr.Row():\n",
        "        with gr.Column():\n",
        "            sentiment_plot_out = gr.Plot()\n",
        "        with gr.Column():\n",
        "            heatmap_plot_out = gr.Plot()\n",
        "\n",
        "    with gr.Row():\n",
        "        with gr.Column():\n",
        "            bar_chart_plot_out = gr.Plot()\n",
        "        with gr.Column():\n",
        "            forecast_plot_out = gr.Plot()\n",
        "\n",
        "    topic_selector.change(\n",
        "        fn=update_dashboard,\n",
        "        inputs=[topic_selector],\n",
        "        outputs=[\n",
        "            summary_out,\n",
        "            ai_output_grid,\n",
        "            sentiment_plot_out,\n",
        "            forecast_plot_out,\n",
        "            heatmap_plot_out,\n",
        "            bar_chart_plot_out\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    demo.load(\n",
        "        fn=lambda: update_dashboard(default_topic),\n",
        "        outputs=[\n",
        "            summary_out,\n",
        "            ai_output_grid,\n",
        "            sentiment_plot_out,\n",
        "            forecast_plot_out,\n",
        "            heatmap_plot_out,\n",
        "            bar_chart_plot_out\n",
        "        ]\n",
        "    )\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    demo.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 732
        },
        "id": "kssIe9j6DKF3",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1757716869929,
          "user_tz": -60,
          "elapsed": 3795,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "b4c417e5-40c5-4621-a1e7-5f5838ff06e9"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3726812152.py:19: DefaultLocationWarning:\n",
            "\n",
            "No explicit location is set, so using location US for the session.\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Query job f7f1b79c-f8c1-490d-a760-a1351042238e is DONE. 0 Bytes processed. <a target=\"_blank\" href=\"https://console.cloud.google.com/bigquery?project=bias-buster-471818&j=bq:US:f7f1b79c-f8c1-490d-a760-a1351042238e&page=queryresults\">Open Job</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://6fafe40106018d14a0.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://6fafe40106018d14a0.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}